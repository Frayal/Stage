{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#created the 17/05/2018 14:14 by Alexis Blanchet#\n",
    "#################################################\n",
    "#-*- coding: utf-8 -*-\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Améliorations possibles:\n",
    "\n",
    "'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#################################################\n",
    "###########        Imports      #################\n",
    "#################################################\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import preprocessing\n",
    "#################################################\n",
    "########### Global variables ####################\n",
    "#################################################\n",
    "\n",
    "#################################################\n",
    "########### Important functions #################\n",
    "#################################################\n",
    "def load(fileX):\n",
    "    df = pd.read_csv('/home/alexis/Bureau/Project/results/truemerge/'+fileX)\n",
    "    y = df['labels']\n",
    "    return df.drop(['labels'],axis=1),y\n",
    "\n",
    "def load_all():\n",
    "    X = pd.DataFrame()\n",
    "    Y = pd.DataFrame()\n",
    "    files = os.listdir('/home/alexis/Bureau/Project/results/truemerge')\n",
    "    for file in files:\n",
    "        df,y = load(file)\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.fillna(0)\n",
    "        X_train = df\n",
    "        y_train = y\n",
    "        X = pd.concat([X,X_train])\n",
    "        Y = pd.concat([Y,y_train])\n",
    "    for f in X.columns:\n",
    "        if X[f].dtype=='object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X[f].values))\n",
    "            X[f] = lbl.transform(list(X[f].values))\n",
    "    return X,Y\n",
    "######################################################\n",
    "######################################################\n",
    "### XGB modeling\n",
    "params = {'eta': 0.001,\n",
    "          'max_depth': 20,\n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 1,\n",
    "          'colsample_bylevel':1,\n",
    "          'min_child_weight':1,\n",
    "          'alpha':5,\n",
    "          'objective': 'multi:softprob',\n",
    "          'eval_metric': 'mlogloss',\n",
    "          'seed': 99,\n",
    "          'silent': 1,\n",
    "         'num_class' : 3,\n",
    "         }\n",
    "params2 = {'eta': 0.001,\n",
    "          'max_depth': 15,\n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 0.9,\n",
    "          'colsample_bylevel':0.9,\n",
    "          'min_child_weight':0.9,\n",
    "          'alpha':5,\n",
    "          'objective': 'multi:softprob',\n",
    "          'eval_metric': 'mlogloss',\n",
    "          'seed': 42,\n",
    "          'silent': 1,\n",
    "          'num_class' : 3,\n",
    "         }\n",
    "######################################################\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        np.random.seed(42)\n",
    "        x1, x2, y1, y2 = train_test_split(X, y, test_size=0.2)\n",
    "        watchlist = [(xgb.DMatrix(x1, y1, weight = [int(y)*2+1 for y in y1]), 'train'), (xgb.DMatrix(x2, y2,weight = [int(y)*2+1 for y in y2]), 'valid')]\n",
    "        self.clf1 = xgb.train(params, (xgb.DMatrix(x1, y1, weight = [int(y)*2+1 for y in y1])), 50000,  watchlist, maximize = False,verbose_eval=500, early_stopping_rounds=3000)\n",
    "        self.clf2 = xgb.train(params2, (xgb.DMatrix(x1, y1, weight = [int(y)*2+1 for y in y1])), 50000,  watchlist, maximize = False,verbose_eval=500, early_stopping_rounds=3000)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        res1 = self.clf1.predict(xgb.DMatrix(X), ntree_limit=self.clf1.best_ntree_limit)\n",
    "        res2 = self.clf2.predict(xgb.DMatrix(X), ntree_limit=self.clf2.best_ntree_limit)\n",
    "        return np.array([[(a[0]+b[0])/2,(a[1]+b[1])/2,(a[2]+b[2])/2] for a,b in zip(res1,res2)])\n",
    "\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "class Classifier2(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        x1, x2, y1, y2 = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "        self.clf1 = CatBoostClassifier(iterations=5000,learning_rate=0.01, depth=11,metric_period = 50, loss_function='MultiClass', eval_metric='MultiClass', random_seed=99, od_type='Iter', od_wait=500,class_weights = [1,3,5])\n",
    "        self.clf1.fit(x1,y1,verbose=True,eval_set=(x2,y2),use_best_model=True)\n",
    "        self.clf2 = CatBoostClassifier(iterations=5000,learning_rate=0.01, depth=12,metric_period = 50, loss_function='MultiClass', eval_metric='MultiClass', random_seed=99, od_type='Iter', od_wait=500,class_weights = [1,3,5])\n",
    "        self.clf2.fit(x1,y1,verbose=True,eval_set=(x2,y2),use_best_model=True)\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.array(np.array([[(a[0]+b[0])/2,(a[1]+b[1])/2,(a[2]+b[2])/2] for a,b in zip(self.clf2.predict_proba(X),self.clf1.predict_proba(X))]))\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "def find_index(l,v):\n",
    "    res = []\n",
    "    for i, j in enumerate(l):\n",
    "        if(j == v):\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "def get_label(y_score,p1=0.5,p2=0.5):\n",
    "    res = []\n",
    "    for i in range(len(y_score)):\n",
    "        #res.append(np.argmax(y_score[i]))\n",
    "        if(y_score[i][1]>p1):\n",
    "            res.append(1)\n",
    "        elif(y_score[i][0]>p2):\n",
    "            res.append(0)\n",
    "        else:\n",
    "            res.append(2)\n",
    "    return res\n",
    "\n",
    "def mesure_class(y_pred,y_true,j):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] == j):\n",
    "            if(y_true[i] == j):\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    for i in range(len(y_true)):\n",
    "        if(y_true[i] == j):\n",
    "            if(y_pred[i] == j):\n",
    "                pass\n",
    "            else:\n",
    "                FN += 1\n",
    "    return TP,FP,FN\n",
    "\n",
    "def score(tp,fp,fn,epsilon=10**-5):\n",
    "    beta = 2\n",
    "    p = tp/(tp+fp+epsilon)\n",
    "    r = tp/(tp+fn+epsilon)\n",
    "    beta_squared = beta ** 2\n",
    "    f = (beta_squared + 1) * (p * r) / (beta_squared * p + r+epsilon)\n",
    "\n",
    "    print(\"|| precison: \"+str(p)+\"|| recall: \"+str(r)+\"|| fbeta: \"+str(f))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "def mesure(y_score,y_test,p1=0.5,p2=0.5):\n",
    "    y = get_label(y_score,p1,p2)\n",
    "    TP1,FP1,FN1 = mesure_class(y,y_test,0)\n",
    "    TP2,FP2,FN2 = mesure_class(y,y_test,1)\n",
    "    TP3,FP3,FN3 = mesure_class(y,y_test,2)\n",
    "    print(\"pour la classe 0\")\n",
    "    score(TP1,FP1,FN1)\n",
    "    print(\"pour la classe 1\")\n",
    "    score(TP2,FP2,FN2)\n",
    "    print(\"pour la classe 2\")\n",
    "    score(TP3,FP3,FN3)\n",
    "\n",
    "def mismatch(y_score,y_test,p1=0.5,p2=0.5):\n",
    "    y = get_label(y_score,p1,p2)\n",
    "    FP = 0\n",
    "    FF = 0\n",
    "    for i in range(len(y)):\n",
    "        if(y[i]==1):\n",
    "            if(y_test[i]==2):\n",
    "                FP += 1\n",
    "            else:\n",
    "                pass\n",
    "        if(y[i]==2):\n",
    "            if(y_test[i]==1):\n",
    "                FF += 1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    print(\"fausses publicités\")\n",
    "    print(FP)\n",
    "    print(\"fausses fins\")\n",
    "    print(FF)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_all()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2612 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "70   0.0\n",
       "85   0.0\n",
       "45   2.0\n",
       "293  0.0\n",
       "39   2.0\n",
       "27   1.0\n",
       "32   0.0\n",
       "13   0.0\n",
       "47   2.0\n",
       "170  0.0\n",
       "146  0.0\n",
       "3    0.0\n",
       "29   2.0\n",
       "60   0.0\n",
       "190  0.0\n",
       "35   0.0\n",
       "75   1.0\n",
       "181  0.0\n",
       "259  0.0\n",
       "79   2.0\n",
       "639  0.0\n",
       "63   1.0\n",
       "84   0.0\n",
       "10   0.0\n",
       "72   1.0\n",
       "50   2.0\n",
       "628  0.0\n",
       "521  0.0\n",
       "20   2.0\n",
       "21   1.0\n",
       "..   ...\n",
       "18   1.0\n",
       "49   1.0\n",
       "30   1.0\n",
       "31   1.0\n",
       "34   0.0\n",
       "627  0.0\n",
       "80   1.0\n",
       "36   2.0\n",
       "13   0.0\n",
       "56   2.0\n",
       "50   0.0\n",
       "15   1.0\n",
       "572  0.0\n",
       "62   0.0\n",
       "8    2.0\n",
       "3    2.0\n",
       "50   0.0\n",
       "42   0.0\n",
       "64   0.0\n",
       "37   1.0\n",
       "491  0.0\n",
       "115  1.0\n",
       "47   0.0\n",
       "49   0.0\n",
       "70   2.0\n",
       "77   2.0\n",
       "53   0.0\n",
       "7    0.0\n",
       "56   0.0\n",
       "59   1.0\n",
       "\n",
       "[2612 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#################################################################\n",
    "def main(argv):\n",
    "    \n",
    "\n",
    "    ##########################################\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train,Y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    clf2 = Classifier2()\n",
    "    clf2.fit(X_train,Y_train)\n",
    "    y_pred2 = clf2.predict_proba(X_test)\n",
    "    ##########################################\n",
    "\n",
    "    print('############XGB##############')\n",
    "    mesure(y_pred,Y_test)\n",
    "    mismatch(y_pred,Y_test)\n",
    "    print('############CatBoost##############')\n",
    "    mesure(y_pred2,Y_test)\n",
    "    mismatch(y_pred2,Y_test)\n",
    "\n",
    "\n",
    "    return (\"process achevé sans erreures\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    main(sys.argv[1:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
